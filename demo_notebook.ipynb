{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **How to run**\n",
        "\n",
        "1.   Run the cell below to load relevent files into the /content folder from a GitHub Repo.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OUhedGfV2WcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/adnanoomerjee/NLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Uz0eBB6V9I",
        "outputId": "4b742311-01b7-4e40-b9a7-566ceaf928e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP'...\n",
            "remote: Enumerating objects: 284, done.\u001b[K\n",
            "remote: Counting objects: 100% (284/284), done.\u001b[K\n",
            "remote: Compressing objects: 100% (199/199), done.\u001b[K\n",
            "remote: Total 284 (delta 152), reused 206 (delta 76), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (284/284), 3.76 MiB | 11.50 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "2.   Go to this [link](https://1drv.ms/f/s!Anyx4brR78Rhg-EwJq7ct_hzETWHXg?e=V7CqoB), containing files too large for either github or moodle.\n",
        "3.  You will see two folders \"Data\" and \"Model\". Download these two folders\n",
        "4.  Navigate to content/NLP/ModelBits in the sidebar.\n",
        "5.  From the two folders in the link, upload the items in the \"Data\" folder to \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ch4uY9nDE9uL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5860JSNqE9a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/NLP/')\n",
        "!pip install -r requirements.txt\n",
        "!pip install transformers\n",
        "os.chdir('/content/NLP/ModelBits')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGJxeS_6-UXb",
        "outputId": "bba80b1d-b4d5-493b-fc79-c1ada7d62f27"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting appnope==0.1.3\n",
            "  Downloading appnope-0.1.3-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting asttokens==2.2.1\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (0.2.0)\n",
            "Collecting backports.functools-lru-cache==1.6.4\n",
            "  Downloading backports.functools_lru_cache-1.6.4-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting blis==0.7.7\n",
            "  Downloading blis-0.7.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Bottleneck==1.3.5\n",
            "  Downloading Bottleneck-1.3.5-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.0/353.0 KB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotlipy==0.7.0\n",
            "  Downloading brotlipy-0.7.0-cp39-cp39-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting catalogue==2.0.7\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (2022.12.7)\n",
            "Requirement already satisfied: cffi==1.15.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (1.15.1)\n",
            "Collecting charset-normalizer==2.0.4\n",
            "  Downloading charset_normalizer-2.0.4-py3-none-any.whl (36 kB)\n",
            "Collecting click==8.0.4\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama==0.4.6\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting cryptography==38.0.4\n",
            "  Downloading cryptography-38.0.4-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cymem==2.0.6\n",
            "  Downloading cymem-2.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
            "Requirement already satisfied: debugpy==1.6.6 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 16)) (1.6.6)\n",
            "Collecting decorator==5.1.1\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting executing==1.2.0\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting filelock==3.9.0\n",
            "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
            "Collecting flit_core==3.6.0\n",
            "  Downloading flit_core-3.6.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface==0.0.1\n",
            "  Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
            "Collecting huggingface-hub==0.12.1\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==3.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 24)) (3.4)\n",
            "Collecting importlib-metadata==6.0.0\n",
            "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
            "Collecting ipykernel==6.15.0\n",
            "  Downloading ipykernel-6.15.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 KB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython==8.11.0\n",
            "  Downloading ipython-8.11.0-py3-none-any.whl (793 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.3/793.3 KB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jedi==0.18.2\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2==3.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 29)) (3.1.2)\n",
            "Collecting joblib==1.2.0\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 KB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter_client==8.0.3\n",
            "  Downloading jupyter_client-8.0.3-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 KB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter_core==5.2.0\n",
            "  Downloading jupyter_core-5.2.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.3/94.3 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langcodes==3.3.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 33)) (3.3.0)\n",
            "Collecting MarkupSafe==2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 35)) (0.1.6)\n",
            "Collecting mkl-fft==1.3.1\n",
            "  Downloading mkl_fft-1.3.1-17-cp39-cp39-manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.4/247.4 KB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mkl-random==1.2.2\n",
            "  Downloading mkl_random-1.2.2-17-cp39-cp39-manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.5/412.5 KB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mkl-service==2.4.0\n",
            "  Downloading mkl_service-2.4.0-11-cp39-cp39-manylinux2014_x86_64.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting murmurhash==1.0.7\n",
            "  Downloading murmurhash-1.0.7-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Requirement already satisfied: nest-asyncio==1.5.6 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 40)) (1.5.6)\n",
            "Requirement already satisfied: numexpr==2.8.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 41)) (2.8.4)\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==22.0\n",
            "  Downloading packaging-22.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.5.2\n",
            "  Downloading pandas-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso==0.8.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 45)) (0.8.3)\n",
            "Requirement already satisfied: pathy==0.10.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 46)) (0.10.1)\n",
            "Requirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 47)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 48)) (0.7.5)\n",
            "Collecting Pillow==9.3.0\n",
            "  Downloading Pillow-9.3.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pip==22.3.1\n",
            "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting platformdirs==3.1.0\n",
            "  Downloading platformdirs-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting preshed==3.0.6\n",
            "  Downloading preshed-3.0.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.1/128.1 KB\u001b[0m \u001b[31m711.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit==3.0.38 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 53)) (3.0.38)\n",
            "Requirement already satisfied: psutil==5.9.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 54)) (5.9.4)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 55)) (0.7.0)\n",
            "Collecting pure-eval==0.2.2\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pycparser==2.21 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 57)) (2.21)\n",
            "Collecting pydantic==1.8.2\n",
            "  Downloading pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pygments==2.14.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 59)) (2.14.0)\n",
            "Collecting pyOpenSSL==22.0.0\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PySocks==1.7.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 61)) (1.7.1)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 62)) (2.8.2)\n",
            "Collecting pytz==2022.7\n",
            "  Downloading pytz-2022.7-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 KB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 64)) (6.0)\n",
            "Collecting pyzmq==25.0.0\n",
            "  Downloading pyzmq-25.0.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex==2022.10.31 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 66)) (2022.10.31)\n",
            "Collecting requests==2.28.1\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.2.1\n",
            "  Downloading scikit_learn-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 69)) (1.10.1)\n",
            "Collecting setuptools==65.6.3\n",
            "  Downloading setuptools-65.6.3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shellingham==1.5.0\n",
            "  Downloading shellingham-1.5.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 72)) (1.16.0)\n",
            "Collecting smart-open==5.2.1\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy==3.3.1\n",
            "  Downloading spacy-3.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-legacy==3.0.9\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Collecting spacy-loggers==1.0.1\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Collecting srsly==2.4.3\n",
            "  Downloading srsly-2.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.6/457.6 KB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stack-data==0.6.2\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting thinc==8.0.15\n",
            "  Downloading thinc-8.0.15-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 KB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 80)) (3.1.0)\n",
            "Collecting tokenizers==0.13.2\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 82)) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision==0.14.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 83)) (0.14.1+cu116)\n",
            "Requirement already satisfied: tornado==6.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 84)) (6.2)\n",
            "Collecting tqdm==4.64.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traitlets==5.9.0\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.26.1\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typer==0.4.1\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Collecting typing_extensions==4.4.0\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting urllib3==1.26.14\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wasabi==0.9.1\n",
            "  Downloading wasabi-0.9.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wcwidth==0.2.6 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 92)) (0.2.6)\n",
            "Collecting wheel==0.38.4\n",
            "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: zipp==3.15.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 94)) (3.15.0)\n",
            "Collecting dpcpp_cpp_rt\n",
            "  Downloading dpcpp_cpp_rt-2023.1.0-py2.py3-none-manylinux1_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mkl in /usr/local/lib/python3.9/dist-packages (from mkl-fft==1.3.1->-r requirements.txt (line 36)) (2019.0)\n",
            "INFO: pip is looking at multiple versions of matplotlib-inline to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting matplotlib-inline==0.1.6\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "INFO: pip is looking at multiple versions of markupsafe to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of langcodes to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langcodes==3.3.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of jupyter-core to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jupyter-client to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of joblib to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jinja2 to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting Jinja2==3.1.2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of jedi to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of ipython to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of ipykernel to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of importlib-metadata to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of idna to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting idna==3.4\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of huggingface to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of flit-core to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of filelock to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of executing to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of decorator to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of debugpy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting debugpy==1.6.6\n",
            "  Downloading debugpy-1.6.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of cymem to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cryptography to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of colorama to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of click to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of charset-normalizer to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cffi to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting cffi==1.15.1\n",
            "  Downloading cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.2/441.2 KB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of certifi to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting certifi==2022.12.7\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 KB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of catalogue to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of brotlipy to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of bottleneck to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of blis to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of backports-functools-lru-cache to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of backcall to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting backcall==0.2.0\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "INFO: pip is looking at multiple versions of asttokens to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of appnope to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install -r requirements.txt (line 36), -r requirements.txt (line 5), -r requirements.txt (line 6) and numpy==1.23.5 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested numpy==1.23.5\n",
            "    blis 0.7.7 depends on numpy>=1.15.0\n",
            "    bottleneck 1.3.5 depends on numpy\n",
            "    mkl-fft 1.3.1 depends on numpy<1.23.0 and >=1.22.3\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Using cached tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0oFb6DjR2FKH"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from get_dataset import Get_Dataset\n",
        "from eval_metrics import eval_run\n",
        "path = os.path.dirname(os.path.abspath('demo_notebook.ipynb'))\n",
        "pd.set_option('display.max_colwidth', None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-fO2uv42FKJ"
      },
      "source": [
        "## Dataset structure\n",
        "\n",
        "The ClaimBuster dataset consists of over 23000 sentences, labelled as NFS, UFS, CFS. Here, we give a brief preview of how the data is structured and how it was processed. The dataset is composed of three parts: all_sentences (containing every sentence from every debate from 1960 to 2016, unlabelled), crowdsourced (containing all crowdsourced labelled examples) and groundtruth (containing all examples labelled by dataset authors).\n",
        "\n",
        "Below we show some examples of the data. The \"Verdict\" column gives the classification of the claim, with -1 = NFS, 0 = UFS, 1 = CFS."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3TsWD0qB2TEX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "rCuJfr3V2FKL",
        "outputId": "ab44cfdf-2cbe-4ef2-ebb5-52531360a155"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7147d9d22eee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_groundtruth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/ClaimBuster_Datasets/datasets/groundtruth.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_all_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/ClaimBuster_Datasets/datasets/all_sentences.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_crowdsourced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/ClaimBuster_Datasets/datasets/crowdsourced.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_groundtruth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/NLP/ModelBits/ClaimBuster_Datasets/datasets/groundtruth.csv'"
          ]
        }
      ],
      "source": [
        "df_groundtruth = pd.read_csv(str(path)+'/ClaimBuster_Datasets/datasets/groundtruth.csv')\n",
        "df_all_sentences = pd.read_csv(str(path)+'/ClaimBuster_Datasets/datasets/all_sentences.csv')\n",
        "df_crowdsourced = pd.read_csv(str(path)+'/ClaimBuster_Datasets/datasets/crowdsourced.csv')\n",
        "\n",
        "df_groundtruth.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T40LSuSZ2FKL"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "We concatenate the groundtruth and crowdsourced CSVs into a single labelled dataset. We then tokenise each sentence in the dataset using a bert-base-cased tokeniser. Finally, the examples in the dataset are organised into a series of triples of sentences, $S_P$, $S_T$, $S_F$, each of which has an associated label for $S_T$, the target sentence we aim to classify. We reindex the labels such that 0 = NFS, 1 = UFS, 2 = CFS.\n",
        "\n",
        "For each $S_T$, the preceding and following sentences are drawn from the \"all_sentences\" dataset, so that all labelled examples have context sentences included even if these context sentences do not possess labels of their own. If the target sentence $S_T$ comes from the first or last line of a respective debate, then its preceding/following contextual sentence is left blank, as we assume independence between debates. \n",
        "\n",
        "Data was preprocessed within the \"Preprocessing.py\" file into an 80:20 train/test split, and training/test sets were saved into the \"Data\" folder. These training and test sets were kept constant throughout the model development process, in order to accurately compare the performance of our models.\n",
        "\n",
        "Shown below are example inputs that are ready to be fed into the model, having been tokenised and concatenated. The full preprocessing code can be found in the \"Preprocessing.py\" file, which processed and saved the dataset. The \"Get_Dataset()\" function extracts the data and prepares it to be fed into the model for training or evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOpChZWk2FKM",
        "outputId": "75a2b3af-8bd5-453b-da96-121a64af3180"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[101, 1109, 4223, 2088, 117, 1103, 7228, 2088, 1104, 1103, 1244, 1311, 1138, 1309, 1151, 1167, 2407, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 4081, 1423, 1141, 1104, 1103, 7885, 12359, 1209, 22366, 1106, 1103, 1864, 1115, 25922, 1110, 1107, 1126, 3432, 1344, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 1262, 25527, 117, 1107, 2538, 1104, 1103, 5910, 1104, 1103, 3331, 4813, 117, 1103, 2978, 4013, 2757, 117, 1177, 4268, 1494, 1366, 1114, 1115, 117, 1150, 2195, 109, 3102, 1550, 1121, 1103, 3331, 4813, 1149, 1104, 1103, 9455, 15906, 3098, 1113, 9468, 19878, 24262, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[101, 1124, 1169, 1294, 1251, 9107, 1119, 3349, 117, 1133, 1103, 9193, 1132, 1115, 1195, 112, 1231, 7914, 1103, 1295, 1104, 8362, 4935, 10105, 6556, 1104, 1412, 1416, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 1262, 1112, 1103, 6556, 1104, 1103, 1416, 1110, 4138, 9658, 117, 5006, 1103, 1155, 24097, 1115, 1195, 1274, 112, 189, 1920, 1105, 1195, 112, 1231, 1280, 1106, 1660, 1948, 1111, 1142, 2199, 1137, 1115, 2199, 1105, 1136, 1111, 1482, 1107, 1103, 1426, 1104, 2245, 1110, 5733, 21321, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 2421, 1143, 1198, 1587, 1128, 1150, 1103, 7141, 1110, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[101, 1135, 112, 188, 1126, 2486, 146, 1221, 170, 1974, 1164, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 146, 1108, 170, 1353, 2949, 1825, 1111, 170, 1229, 1107, 1745, 2245, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 1188, 1110, 1126, 3469, 1115, 112, 188, 1125, 1185, 2197, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[101, 1262, 1103, 1314, 1645, 146, 112, 173, 1176, 1106, 1474, 1110, 1142, 131, 1188, 9478, 2239, 1114, 1103, 2461, 1913, 1107, 112, 5117, 1108, 6434, 117, 1105, 1828, 119, 4100, 1189, 1146, 1111, 1122, 1114, 1210, 9712, 6824, 2758, 1279, 117, 1141, 1222, 1412, 1319, 11989, 1107, 1999, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 1337, 112, 188, 1136, 1103, 1236, 1106, 1576, 1412, 2880, 2818, 117, 1259, 1835, 2597, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 2958, 117, 146, 112, 173, 1176, 1106, 3368, 1146, 1113, 1115, 1553, 117, 2140, 117, 1105, 1113, 1240, 5767, 1111, 170, 3407, 4929, 1104, 1237, 7891, 1863, 1107, 2880, 5707, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[101, 1327, 4418, 1547, 1103, 1397, 2084, 1202, 14863, 118, 1107, 1103, 1856, 1104, 1126, 14863, 118, 1126, 15299, 1216, 1112, 2743, 2977, 1137, 1103, 5953, 118, 4073, 3465, 118, 22233, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 1622, 1103, 2484, 7587, 1104, 25827, 117, 148, 11680, 22680, 2137, 3663, 131, 2119, 1519, 1143, 1474, 1115, 146, 1341, 1115, 1103, 2084, 5049, 1107, 170, 1295, 1104, 1472, 1877, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 1752, 117, 1112, 170, 7663, 2301, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Sentences  \\\n",
              "0                          [[101, 1109, 4223, 2088, 117, 1103, 7228, 2088, 1104, 1103, 1244, 1311, 1138, 1309, 1151, 1167, 2407, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 4081, 1423, 1141, 1104, 1103, 7885, 12359, 1209, 22366, 1106, 1103, 1864, 1115, 25922, 1110, 1107, 1126, 3432, 1344, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 1262, 25527, 117, 1107, 2538, 1104, 1103, 5910, 1104, 1103, 3331, 4813, 117, 1103, 2978, 4013, 2757, 117, 1177, 4268, 1494, 1366, 1114, 1115, 117, 1150, 2195, 109, 3102, 1550, 1121, 1103, 3331, 4813, 1149, 1104, 1103, 9455, 15906, 3098, 1113, 9468, 19878, 24262, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]]   \n",
              "1                  [[101, 1124, 1169, 1294, 1251, 9107, 1119, 3349, 117, 1133, 1103, 9193, 1132, 1115, 1195, 112, 1231, 7914, 1103, 1295, 1104, 8362, 4935, 10105, 6556, 1104, 1412, 1416, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 1262, 1112, 1103, 6556, 1104, 1103, 1416, 1110, 4138, 9658, 117, 5006, 1103, 1155, 24097, 1115, 1195, 1274, 112, 189, 1920, 1105, 1195, 112, 1231, 1280, 1106, 1660, 1948, 1111, 1142, 2199, 1137, 1115, 2199, 1105, 1136, 1111, 1482, 1107, 1103, 1426, 1104, 2245, 1110, 5733, 21321, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 2421, 1143, 1198, 1587, 1128, 1150, 1103, 7141, 1110, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]]   \n",
              "2                                                                                                                                                                                 [[101, 1135, 112, 188, 1126, 2486, 146, 1221, 170, 1974, 1164, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 146, 1108, 170, 1353, 2949, 1825, 1111, 170, 1229, 1107, 1745, 2245, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 1188, 1110, 1126, 3469, 1115, 112, 188, 1125, 1185, 2197, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]]   \n",
              "3  [[101, 1262, 1103, 1314, 1645, 146, 112, 173, 1176, 1106, 1474, 1110, 1142, 131, 1188, 9478, 2239, 1114, 1103, 2461, 1913, 1107, 112, 5117, 1108, 6434, 117, 1105, 1828, 119, 4100, 1189, 1146, 1111, 1122, 1114, 1210, 9712, 6824, 2758, 1279, 117, 1141, 1222, 1412, 1319, 11989, 1107, 1999, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 1337, 112, 188, 1136, 1103, 1236, 1106, 1576, 1412, 2880, 2818, 117, 1259, 1835, 2597, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 2958, 117, 146, 112, 173, 1176, 1106, 3368, 1146, 1113, 1115, 1553, 117, 2140, 117, 1105, 1113, 1240, 5767, 1111, 170, 3407, 4929, 1104, 1237, 7891, 1863, 1107, 2880, 5707, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]]   \n",
              "4                                                                      [[101, 1327, 4418, 1547, 1103, 1397, 2084, 1202, 14863, 118, 1107, 1103, 1856, 1104, 1126, 14863, 118, 1126, 15299, 1216, 1112, 2743, 2977, 1137, 1103, 5953, 118, 4073, 3465, 118, 22233, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 1622, 1103, 2484, 7587, 1104, 25827, 117, 148, 11680, 22680, 2137, 3663, 131, 2119, 1519, 1143, 1474, 1115, 146, 1341, 1115, 1103, 2084, 5049, 1107, 170, 1295, 1104, 1472, 1877, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], [101, 1752, 117, 1112, 170, 7663, 2301, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]]   \n",
              "\n",
              "   Labels  \n",
              "0       0  \n",
              "1       2  \n",
              "2       1  \n",
              "3       0  \n",
              "4       0  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainset = Get_Dataset(train=True)\n",
        "processed_examples = pd.DataFrame({'Sentences': trainset.sentences.tolist(), 'Labels': trainset.labels.tolist()})\n",
        "processed_examples.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qaqhcjy12FKM"
      },
      "source": [
        "## Model architectures\n",
        "\n",
        "Detailed below are the model architectures for which we will investigate performance. Full code for each model can be found in the \"network.py\" file\n",
        "\n",
        "#### Network 0 (baseline):\n",
        "\n",
        "Inputs: [$S_T$]\n",
        "\n",
        "Outputs: y $\\in$ {0,1}\n",
        "\n",
        "Network with single BERT embedding layer, followed by MLP (as in the ClaimBuster Adversarial Transformer paper)\n",
        "* Embeds the target sentence using a BERT transformer.\n",
        "* Passes pooled output (CLS tokens) through a two layer MLP.\n",
        "* Outputs binary classification where 0 = NFS or UFS, 1 = CFS \n",
        "\n",
        "#### Network 1:\n",
        "\n",
        "Inputs: [$S_P$, $S_T$, $S_F$]\n",
        "\n",
        "Outputs: y $\\in$ {0,1,2}\n",
        "\n",
        "Network with 3 parallel BERT embedding layers, followed by LSTM layer and MLP layer\n",
        "* Embeds three sentences using BERT transformers.\n",
        "* Passes pooled outputs (CLS tokens) of each sentencea s a sequence to a Bi-LSTM. \n",
        "* Takes middle hidden state of Bi-LSTM and passes through a two layer MLP.\n",
        "* Outputs multiclass classification where 0 = NFS, 1 = UFS, 2 = CFS \n",
        "\n",
        "#### Network 2:\n",
        "\n",
        "Inputs: [$S_P$, $S_T$, $S_F$]\n",
        "\n",
        "Outputs: y $\\in$ {0,1,2}\n",
        "\n",
        "Network with 3 parallel BERT embedding layers, followed by attention layer and MLP layer\n",
        "* Embeds three sentences using BERT transformers.\n",
        "* Passes pooled outputs (CLS tokens) into two attention heads, computing attention between (S_T, S_P) and (S_T, S_F). \n",
        "* Concatenates outputs of attention heads and passes through a two layer MLP.\n",
        "* Outputs multiclass classification where 0 = NFS, 1 = UFS, 2 = CFS \n",
        "\n",
        "#### Network 3:\n",
        "\n",
        "Inputs: [$S_P$, $S_T$, $S_F$]\n",
        "\n",
        "Outputs: y $\\in$ {0,1,2}\n",
        "\n",
        "Network with 3 parallel BERT embedding layers, followed by attention layer and MLP layer\n",
        "* Embeds three sentences using BERT transformers.\n",
        "* Passes pooled outputs (CLS tokens) into two attention heads, computing attention between (S_T, S_P) and (S_T, S_F). \n",
        "* Concatenates outputs of attention heads AND S_T output of BERT layer and passes through a two layer MLP.\n",
        "* Outputs multiclass classification where 0 = NFS, 1 = UFS, 2 = CFS \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C7dEZwh2FKM"
      },
      "source": [
        "## Training\n",
        "\n",
        "The models were trained using the train.py file. The models were trained for 15 epochs with a batch size of 4. A basic SGD optimiser with a learning rate of 0.001 was used, as this was found to converge better than other optimisers in early experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDgSIFLC2FKN"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "For each model, we evaluate by computing the precision, recall and F1 scores for each class on the test set, as well as overall weighted avergage P, R, F1. We also output the confusion matrices for each model. Tests for each model can be run in the cells below, with metrics printed in the output. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPq90Soq2FKN"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This cell calls the eval_run function from the eval_metrics file\n",
        "Precision, Recall, F1 arrays are ordered by the respective classes in the format \"array([0,1,2])\".\n",
        "\n",
        "If you would like to view the outputs in a csv file, pass the argument \"save=True\" into the function call below.\n",
        "\"\"\"\n",
        "eval_run()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NLP00",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}